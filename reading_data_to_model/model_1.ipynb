{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caring-shoot",
   "metadata": {},
   "source": [
    "# Roles: Multi-label Single-class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "greenhouse-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-instrument",
   "metadata": {},
   "source": [
    "## Loading & Preprocessing of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fitting-twenty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annotations</th>\n",
       "      <th>Path</th>\n",
       "      <th>Manuscript</th>\n",
       "      <th>Description</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>saint</th>\n",
       "      <th>prophet</th>\n",
       "      <th>king</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['initiale historiee', 'lettre f', 'lettre a p...</td>\n",
       "      <td>1366264.jpg</td>\n",
       "      <td>Paris, Bibl. Mazarine, 0018</td>\n",
       "      <td>saint jerome ecrivant</td>\n",
       "      <td>['saint']</td>\n",
       "      <td>['1366264']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['initiale historiee', 'lettre f', 'lettre a p...</td>\n",
       "      <td>1366263.jpg</td>\n",
       "      <td>Paris, Bibl. Mazarine, 0018</td>\n",
       "      <td>saint jerome ecrivant</td>\n",
       "      <td>['saint']</td>\n",
       "      <td>['1366263']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Annotations         Path  \\\n",
       "0  ['initiale historiee', 'lettre f', 'lettre a p...  1366264.jpg   \n",
       "1  ['initiale historiee', 'lettre f', 'lettre a p...  1366263.jpg   \n",
       "\n",
       "                    Manuscript            Description      label           id  \\\n",
       "0  Paris, Bibl. Mazarine, 0018  saint jerome ecrivant  ['saint']  ['1366264']   \n",
       "1  Paris, Bibl. Mazarine, 0018  saint jerome ecrivant  ['saint']  ['1366263']   \n",
       "\n",
       "   saint  prophet  king  \n",
       "0      1        0     0  \n",
       "1      1        0     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('r.csv')    # reading the csv file\n",
    "train.head(2)      # printing first five rows of the file"
   ]
  },
  {
   "cell_type": "raw",
   "id": "determined-burns",
   "metadata": {},
   "source": [
    "dataTypeSeries = train.dtypes\n",
    "print('Data type of each column of Dataframe :')\n",
    "print(dataTypeSeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "elementary-status",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['prophet']\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "focused-croatia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1791, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(train.drop(['Annotations','Path','Manuscript','Description','id','saint','prophet','king'],axis=1))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "proud-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a class vector (integers) to binary class matrix\n",
    "# y = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "neural-wrestling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1791, 1)\n",
      "[[\"['saint']\"]\n",
      " [\"['saint']\"]\n",
      " [\"['prophet']\"]\n",
      " ...\n",
      " [\"['king']\"]\n",
      " [\"['king']\"]\n",
      " [\"['king']\"]]\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-rhythm",
   "metadata": {},
   "source": [
    "## Loading & Preprocessing of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "painful-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "#Import from keras_preprocessing not from keras.preprocessing\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "raw",
   "id": "facial-australian",
   "metadata": {},
   "source": [
    "def append_ext(fn):\n",
    "    return fn+\".png\"\n",
    "traindf=pd.read_csv(“./trainLabels.csv”,dtype=str)\n",
    "testdf=pd.read_csv(\"./sampleSubmission.csv\",dtype=str)\n",
    "traindf[\"id\"]=traindf[\"id\"].apply(append_ext)\n",
    "testdf[\"id\"]=testdf[\"id\"].apply(append_ext)\n",
    "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expensive-georgia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1791/1791 [01:25<00:00, 20.99it/s]\n"
     ]
    }
   ],
   "source": [
    "train_image = []\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    #\"C:/Users/yhawa/OneDrive/masters_thesis_2022/Initiale_clean/hand_gestures/filtered_imageshand_gestures_new/\"\n",
    "    img = image.load_img('C:/Users/yhawa/OneDrive/masters_thesis_2022/Initiale_clean/roles/personspersons_new/'+train['Path'][i],target_size=(400,400,3))\n",
    "    img = image.img_to_array(img)\n",
    "    #reshape images\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "X = np.array(train_image)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "precious-sucking",
   "metadata": {},
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "violent-eating",
   "metadata": {},
   "source": [
    "plt.imshow(X[118])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-satisfaction",
   "metadata": {},
   "source": [
    "## Split Train and Test Data 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "vanilla-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "photographic-relevance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1432, 400, 400, 3) (1432, 1)\n",
      "(359, 400, 400, 3) (359, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-compiler",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "threaded-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\", input_shape=(400,400,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "induced-mauritius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 396, 396, 16)      1216      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 198, 198, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 198, 198, 16)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 194, 194, 32)      12832     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 97, 97, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 97, 97, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 93, 93, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 46, 46, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 46, 46, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 42, 42, 64)        102464    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 21, 21, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 21, 21, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 28224)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3612800   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,789,027\n",
      "Trainable params: 3,789,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-funds",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "after-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "missing-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "postal-logistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EAA1988D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EAA1988D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes (None, 1) and (None, 3) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-fe38f87c2df4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\aml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\aml\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m   5081\u001b[0m   \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5082\u001b[0m   \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5083\u001b[1;33m   \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5085\u001b[0m   \u001b[1;31m# Use logits whenever they are available. `softmax` and `sigmoid`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (None, 1) and (None, 3) are incompatible"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
